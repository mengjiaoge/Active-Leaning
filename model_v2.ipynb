{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from scipy import stats\n",
    "from pylab import rcParams\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, \\\n",
    "    GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gmjsl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data  = pd.read_csv('data/train.tsv', sep='\\t', encoding = \"ISO-8859-1\")\\\n",
    "             .rename(columns={'Score1': 'EssayScore'})\n",
    "\n",
    "X_test_data = pd.read_csv('data/public_leaderboard.tsv', sep='\\t', encoding = \"ISO-8859-1\")  \n",
    "y_test_data = pd.read_csv('data/public_leaderboard_solution.csv', sep=',', encoding = \"ISO-8859-1\")\\\n",
    "             .rename(columns={'id': 'Id', 'essay_set': 'EssaySet', 'essay_score': 'EssayScore' })\\\n",
    "            [['Id', 'EssaySet', 'EssayScore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>EssayScore</th>\n",
       "      <th>Score2</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Some additional information that we would need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>After reading the expirement, I realized that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What you need is more trials, a control set up...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  EssaySet  EssayScore  Score2  \\\n",
       "0   1         1           1       1   \n",
       "1   2         1           1       1   \n",
       "2   3         1           1       1   \n",
       "\n",
       "                                           EssayText  \n",
       "0  Some additional information that we would need...  \n",
       "1  After reading the expirement, I realized that ...  \n",
       "2  What you need is more trials, a control set up...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>The procedures I think they should have includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>In order to replicate this experiment, you wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675</td>\n",
       "      <td>1</td>\n",
       "      <td>In order to replicate their experiment, you wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  EssaySet                                          EssayText\n",
       "0  1673         1  The procedures I think they should have includ...\n",
       "1  1674         1  In order to replicate this experiment, you wou...\n",
       "2  1675         1  In order to replicate their experiment, you wo..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>EssayScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  EssaySet  EssayScore\n",
       "0  1673         1           1\n",
       "1  1674         1           1\n",
       "2  1675         1           3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit_predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SvmModel(BaseModel):\n",
    "\n",
    "    model_type = 'Support Vector Machine with linear Kernel'\n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training svm...')\n",
    "        self.classifier = SVC(C=1, kernel='linear', probability=True,\n",
    "                              class_weight=c_weight)\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.classifier.predict(X_test)\n",
    "        self.val_y_predicted = self.classifier.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
    "                self.test_y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogModel(BaseModel):\n",
    "\n",
    "    model_type = 'Multinominal Logistic Regression' \n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training multinomial logistic regression')\n",
    "        train_samples = X_train.shape[0]\n",
    "        self.classifier = LogisticRegression(\n",
    "            C=50. / train_samples,\n",
    "            multi_class='multinomial',\n",
    "            penalty='l1',\n",
    "            solver='saga',\n",
    "            tol=0.1,\n",
    "            class_weight=c_weight,\n",
    "            )\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.classifier.predict(X_test)\n",
    "        self.val_y_predicted = self.classifier.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
    "                self.test_y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfModel(BaseModel):\n",
    "\n",
    "    model_type = 'Random Forest'\n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training random forest...')\n",
    "        self.classifier = RandomForestClassifier(n_estimators=500, class_weight=c_weight)\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.classifier.predict(X_test)\n",
    "        self.val_y_predicted = self.classifier.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "\n",
    "    def __init__(self, model_object):        \n",
    "        self.accuracies = []\n",
    "        self.model_object = model_object()        \n",
    "\n",
    "    def print_model_type(self):\n",
    "        print (self.model_object.model_type)\n",
    "\n",
    "    # Train normally and get probabilities for the validation set. \n",
    "    # i.e.Use the probabilities to select the most uncertain samples\n",
    "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('Train set:', X_train.shape, 'y:', y_train.shape)\n",
    "        print ('Val set:', X_val.shape)\n",
    "        print ('Test set:', X_test.shape)\n",
    "        t0 = time.time()\n",
    "        (X_train, X_val, X_test, self.val_y_predicted,\n",
    "         self.test_y_predicted) = \\\n",
    "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
    "        self.run_time = time.time() - t0\n",
    "        return (X_train, X_val, X_test)  # return them in case we use PCA, with all the other algorithms, this is not needed.\n",
    "\n",
    "    # Calculate accuracy only for the test set\n",
    "    def get_test_accuracy(self, i, y_test):\n",
    "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
    "        self.accuracies.append(classif_rate)               \n",
    "        print('--------------------------------')\n",
    "        print('Iteration:',i)\n",
    "        print('--------------------------------')\n",
    "        print('y-test set:',y_test.shape)\n",
    "        print('Example run in %.3f s' % self.run_time,'\\n')\n",
    "        print(\"Accuracy rate for %f \" % (classif_rate))    \n",
    "        print(\"Classification report for classifier %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSelectionFunction(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        random_state = check_random_state(0)\n",
    "        selection = np.random.choice(probas_val.shape[0], initial_labeled_samples, replace=False)\n",
    "\n",
    "#     print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',initial_labeled_samples)\n",
    "\n",
    "        return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropySelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
    "        selection = (np.argsort(e)[::-1])[:initial_labeled_samples]\n",
    "        return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginSamplingSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        rev = np.sort(probas_val, axis=1)[:, ::-1]\n",
    "        values = rev[:, 0] - rev[:, 1]\n",
    "        selection = np.argsort(values)[:initial_labeled_samples]\n",
    "        return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \n",
    "    def normalize(self, X_train, X_val, X_test):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        X_val   = self.scaler.transform(X_val)\n",
    "        X_test  = self.scaler.transform(X_test)\n",
    "        return (X_train, X_val, X_test) \n",
    "    \n",
    "    def inverse(self, X_train, X_val, X_test):\n",
    "        X_train = self.scaler.inverse_transform(X_train)\n",
    "        X_val   = self.scaler.inverse_transform(X_val)\n",
    "        X_test  = self.scaler.inverse_transform(X_test)\n",
    "        return (X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO \n",
    "# create a class called data to include the following 3 methods\n",
    "# get_train_data_per_prompt, get_test_data_per_prompt, get_k_random_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data_per_prompt(i, trainset):\n",
    "    X_train_cols = ['Id', 'EssaySet', 'EssayText']\n",
    "    y_train_cols = ['EssayScore']\n",
    "    \n",
    "    X_train_full_per_prompt = trainset.loc[trainset['EssaySet']==i][X_train_cols]\n",
    "    y_train_full_per_prompt = trainset.loc[trainset['EssaySet']==i][y_train_cols]\n",
    "    \n",
    "    X_train_full_per_prompt.reset_index(drop=True, inplace=True)\n",
    "    y_train_full_per_prompt.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return (X_train_full_per_prompt, y_train_full_per_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_per_prompt(i, X_test_data, y_test_data):\n",
    "    X_test_full_per_prompt = X_test_data.loc[X_test_data['EssaySet']==i]\n",
    "    y_test_full_per_prompt = y_test_data.loc[y_test_data['EssaySet']==i]\n",
    "    return (X_test_full_per_prompt, y_test_full_per_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_random_samples(i, initial_labeled_samples, trainset):\n",
    "    \n",
    "    X_train_per_prompt, y_train_per_prompt = get_train_data_per_prompt(i=i, trainset=trainset)\n",
    "\n",
    "    trainset_size = len(X_train_per_prompt)\n",
    "    random_state = check_random_state(0)\n",
    "    random_idx = np.random.choice(trainset_size-1,\n",
    "                                   initial_labeled_samples,\n",
    "                                   replace=False)\n",
    "\n",
    "    X_train = X_train_per_prompt[X_train_per_prompt.index.isin(random_idx)]\n",
    "    y_train = y_train_per_prompt[y_train_per_prompt.index.isin(random_idx)]\n",
    "    \n",
    "    # Reset the train set index\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return (random_idx, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheAlgorithm(object):\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    def __init__(self, prompt, initial_labeled_samples, model_object, selection_function):\n",
    "        self.prompt = prompt\n",
    "        self.initial_labeled_samples = initial_labeled_samples\n",
    "        self.model_object = model_object\n",
    "        self.sample_selection_function = selection_function\n",
    "\n",
    "    def run(self, train_data, X_test_data, y_test_data):\n",
    "\n",
    "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
    "\n",
    "        (random_idx, X_train, y_train) = get_k_random_samples(self.prompt, self.initial_labeled_samples, train_data)\n",
    "        (X_test, y_test) = get_test_data_per_prompt(self.prompt, X_test_data, y_test_data)\n",
    "        \n",
    "        self.queried = self.initial_labeled_samples\n",
    "        self.samplecount = [self.initial_labeled_samples]\n",
    "\n",
    "        # assign the val set the rest of the 'unlabelled' training data\n",
    "        \n",
    "        # initial the val set\n",
    "        X_val = np.array([])\n",
    "        y_val = np.array([])\n",
    "        \n",
    "        # val set = unlabeled pool set - initial labeled set\n",
    "        X_val = np.copy(X_train_full)\n",
    "        X_val = np.delete(X_val, permutation, axis=0)\n",
    "        \n",
    "        y_val = np.copy(y_train_full)\n",
    "        y_val = np.delete(y_val, permutation, axis=0)\n",
    "        \n",
    "        print('val set:', X_val.shape, y_val.shape, permutation.shape)\n",
    " \n",
    "        # normalize data\n",
    "        normalizer = Normalize()\n",
    "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
    "        \n",
    "        self.clf_model = TrainModel(self.model_object)\n",
    "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
    "        active_iteration = 1\n",
    "        self.clf_model.get_test_accuracy(1, y_test)\n",
    "\n",
    "        while self.queried < max_queried:\n",
    "\n",
    "            active_iteration += 1\n",
    "\n",
    "            # get validation probabilities\n",
    "            probas_val = self.clf_model.model_object.classifier.predict_proba(X_val)\n",
    "\n",
    "            # select samples using a selection function\n",
    "            uncertain_samples = self.sample_selection_function.select(probas_val, self.initial_labeled_samples)\n",
    "\n",
    "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
    "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
    "\n",
    "            # get the uncertain samples from the validation set\n",
    "            print ('trainset before', X_train.shape, y_train.shape)\n",
    "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
    "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
    "            print ('trainset after', X_train.shape, y_train.shape)\n",
    "            self.samplecount.append(X_train.shape[0])\n",
    "\n",
    "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
    "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
    "            print ('val set:', X_val.shape, y_val.shape)\n",
    "            print ()\n",
    "\n",
    "            # normalize again after creating the 'new' train/test sets\n",
    "            normalizer = Normalize()\n",
    "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
    "\n",
    "            self.queried += self.initial_labeled_samples\n",
    "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
    "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
    "\n",
    "        print('final active learning accuracies', self.clf_model.accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopping at: 2000\n",
      "Count = 1, using model = SvmModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
      "val set: (17197, 3) (17197, 1) (10,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'First thing the mRNA does is go to the ribosome.  Next, the tRNA comes and decodes the first three nucleotides.  Then, the tRNA brings over the amino acid that matches the codon.  Last, the tRNA shifts over and the amino acids form peptide bonds with one another.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-fd45a9d0988b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mstopped_at\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselection_functions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopped_at\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-134-fd45a9d0988b>\u001b[0m in \u001b[0;36mexperiment\u001b[1;34m(d, prompt, models, selection_functions, Ks, repeats, contfrom)\u001b[0m\n\u001b[0;32m     39\u001b[0m                                        \u001b[0mselection_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                                        )\n\u001b[1;32m---> 41\u001b[1;33m                     \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m                     \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselection_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                     \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Active-learning-experiment-'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-133-505da6600b8d>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, train_data, X_test_data, y_test_data)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# normalize data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mnormalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-35e4488c8735>\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(self, X_train, X_val, X_test)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mX_val\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mX_test\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    691\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_samples_seen_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         X = self._validate_data(X, reset=first_pass,\n\u001b[0m\u001b[0;32m    370\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m                                 force_all_finite=\"allow-nan\")\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1781\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1783\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'First thing the mRNA does is go to the ribosome.  Next, the tRNA comes and decodes the first three nucleotides.  Then, the tRNA brings over the amino acid that matches the codon.  Last, the tRNA shifts over and the amino acids form peptide bonds with one another.'"
     ]
    }
   ],
   "source": [
    "def pickle_save(fname, data):\n",
    "  filehandler = open(fname,\"wb\")\n",
    "  pickle.dump(data,filehandler)\n",
    "  filehandler.close() \n",
    "  print('saved', fname, os.getcwd(), os.listdir())\n",
    "\n",
    "def pickle_load(fname):\n",
    "  print(os.getcwd(), os.listdir())\n",
    "  file = open(fname,'rb')\n",
    "  data = pickle.load(file)\n",
    "  file.close()\n",
    "  print(data)\n",
    "  return data\n",
    "\n",
    "\n",
    "def experiment(d, prompt, models, selection_functions, Ks, repeats, contfrom):\n",
    "    algos_temp = []\n",
    "    print ('stopping at:', max_queried)\n",
    "    count = 0\n",
    "    \n",
    "    for model_object in models:\n",
    "      if model_object.__name__ not in d:\n",
    "          d[model_object.__name__] = {}\n",
    "      \n",
    "      for selection_function in selection_functions:\n",
    "        if selection_function.__name__ not in d[model_object.__name__]:\n",
    "            d[model_object.__name__][selection_function.__name__] = {}\n",
    "        \n",
    "        for k in Ks:\n",
    "            d[model_object.__name__][selection_function.__name__][str(k)] = []           \n",
    "            \n",
    "            for i in range(0, repeats):\n",
    "                count+=1\n",
    "                if count >= contfrom:\n",
    "                    print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
    "                    alg = TheAlgorithm(prompt,\n",
    "                                       k, \n",
    "                                       model_object, \n",
    "                                       selection_function\n",
    "                                       )\n",
    "                    alg.run(train_data, X_test_data, y_test_data)\n",
    "                    d[model_object.__name__][selection_function.__name__][str(k)].append(alg.clf_model.accuracies)\n",
    "                    fname = 'Active-learning-experiment-' + str(count) + '.pkl'\n",
    "                    pickle_save(fname, d)\n",
    "                    if count % 5 == 0:\n",
    "                        print(json.dumps(d, indent=2, sort_keys=True))\n",
    "                    print ()\n",
    "                    print ('---------------------------- FINISHED ---------------------------')\n",
    "                    print ()\n",
    "    return d\n",
    "\n",
    "\n",
    "max_queried = 2000 \n",
    "\n",
    "repeats = 1\n",
    "\n",
    "prompt = 5\n",
    "\n",
    "models = [SvmModel, RfModel, LogModel] \n",
    "\n",
    "selection_functions = [RandomSelection, MarginSamplingSelection, EntropySelection] \n",
    "\n",
    "Ks = [250,125,50,25,10] \n",
    "\n",
    "d = {}\n",
    "stopped_at = -1 \n",
    "\n",
    "d = experiment(d, prompt, models, selection_functions, Ks, repeats, stopped_at+1)\n",
    "print (d)\n",
    "results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
