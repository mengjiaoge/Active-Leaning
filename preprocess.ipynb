{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gmjsl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import re \n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to clean the text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "def tokenize(text):\n",
    "    text = tokenizer.tokenize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = [word for word in text if word not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(text):\n",
    "    text = [lemmatizer.lemmatize(token) for token in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing functions \n",
    "def text_preprocessing(text):\n",
    "    # Clean up text\n",
    "    nopunc = clean_text(text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_text = tokenize(nopunc)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    removed_stopwords_text = remove_stopwords(tokenized_text)\n",
    "    \n",
    "    # Lemmatize\n",
    "    lemmatized_text = lemmatize(removed_stopwords_text)\n",
    "    \n",
    "    combined_text = ' '.join(lemmatized_text)\n",
    "    \n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_vectors(essays):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.9)\n",
    "    \n",
    "    tfidf_vectors = vectorizer.fit_transform(essays)\n",
    "    \n",
    "    print(tfidf_vectors)\n",
    "    \n",
    "    return pd.DataFrame(tfidf_vectors.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set  = pd.read_csv('data/train.tsv', sep='\\t', encoding = \"ISO-8859-1\")\\\n",
    "             .rename(columns={'Score1': 'EssayScore'})\n",
    "train_set = train_set[['Id', 'EssaySet', 'EssayText', 'EssayScore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_sample = train_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-bb668f781ca3>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set_sample['EssayText'] = train_set_sample['EssayText'].apply(lambda x: text_preprocessing(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>EssayScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>additional information would need replicate ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>reading expirement realized additional informa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>need trial control set exact amount vinegar po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  EssaySet                                          EssayText  EssayScore\n",
       "0   1         1  additional information would need replicate ex...           1\n",
       "1   2         1  reading expirement realized additional informa...           1\n",
       "2   3         1  need trial control set exact amount vinegar po...           1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_sample['EssayText'] = train_set_sample['EssayText'].apply(lambda x: text_preprocessing(x))\n",
    "train_set_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 131)\t0.11176931709391921\n",
      "  (0, 63)\t0.11176931709391921\n",
      "  (0, 126)\t0.11176931709391921\n",
      "  (0, 162)\t0.11176931709391921\n",
      "  (0, 171)\t0.11176931709391921\n",
      "  (0, 41)\t0.11176931709391921\n",
      "  (0, 91)\t0.11176931709391921\n",
      "  (0, 129)\t0.11176931709391921\n",
      "  (0, 38)\t0.11176931709391921\n",
      "  (0, 61)\t0.11176931709391921\n",
      "  (0, 83)\t0.11176931709391921\n",
      "  (0, 86)\t0.11176931709391921\n",
      "  (0, 160)\t0.11176931709391921\n",
      "  (0, 151)\t0.11176931709391921\n",
      "  (0, 24)\t0.11176931709391921\n",
      "  (0, 67)\t0.11176931709391921\n",
      "  (0, 104)\t0.11176931709391921\n",
      "  (0, 164)\t0.11176931709391921\n",
      "  (0, 93)\t0.11176931709391921\n",
      "  (0, 50)\t0.11176931709391921\n",
      "  (0, 119)\t0.11176931709391921\n",
      "  (0, 95)\t0.11176931709391921\n",
      "  (0, 174)\t0.11176931709391921\n",
      "  (0, 72)\t0.11176931709391921\n",
      "  (0, 4)\t0.11176931709391921\n",
      "  :\t:\n",
      "  (2, 31)\t0.14812230607912677\n",
      "  (2, 34)\t0.14812230607912677\n",
      "  (2, 106)\t0.14812230607912677\n",
      "  (2, 165)\t0.14812230607912677\n",
      "  (2, 12)\t0.14812230607912677\n",
      "  (2, 46)\t0.14812230607912677\n",
      "  (2, 133)\t0.14812230607912677\n",
      "  (2, 28)\t0.14812230607912677\n",
      "  (2, 153)\t0.14812230607912677\n",
      "  (2, 97)\t0.14812230607912677\n",
      "  (2, 64)\t0.14812230607912677\n",
      "  (2, 87)\t0.14812230607912677\n",
      "  (2, 42)\t0.14812230607912677\n",
      "  (2, 14)\t0.14812230607912677\n",
      "  (2, 141)\t0.14812230607912677\n",
      "  (2, 5)\t0.14812230607912677\n",
      "  (2, 30)\t0.14812230607912677\n",
      "  (2, 33)\t0.14812230607912677\n",
      "  (2, 105)\t0.14812230607912677\n",
      "  (2, 11)\t0.14812230607912677\n",
      "  (2, 45)\t0.14812230607912677\n",
      "  (2, 132)\t0.14812230607912677\n",
      "  (2, 27)\t0.14812230607912677\n",
      "  (2, 152)\t0.14812230607912677\n",
      "  (2, 79)\t0.11265083169274666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accurate</th>\n",
       "      <th>additional</th>\n",
       "      <th>additional information</th>\n",
       "      <th>additional information need</th>\n",
       "      <th>additional information would</th>\n",
       "      <th>also</th>\n",
       "      <th>also take</th>\n",
       "      <th>also take check</th>\n",
       "      <th>amant</th>\n",
       "      <th>amant vinegar</th>\n",
       "      <th>...</th>\n",
       "      <th>would need</th>\n",
       "      <th>would need replicate</th>\n",
       "      <th>write</th>\n",
       "      <th>write conclusion</th>\n",
       "      <th>write conclusion make</th>\n",
       "      <th>yar</th>\n",
       "      <th>yar expirement</th>\n",
       "      <th>yar expirement three</th>\n",
       "      <th>yar result</th>\n",
       "      <th>yar result accurate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085003</td>\n",
       "      <td>0.085003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111769</td>\n",
       "      <td>0.111769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113079</td>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.113079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113079</td>\n",
       "      <td>0.113079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113079</td>\n",
       "      <td>0.113079</td>\n",
       "      <td>0.113079</td>\n",
       "      <td>0.226158</td>\n",
       "      <td>0.113079</td>\n",
       "      <td>0.113079</td>\n",
       "      <td>0.113079</td>\n",
       "      <td>0.113079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148122</td>\n",
       "      <td>0.148122</td>\n",
       "      <td>0.148122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accurate  additional  additional information  additional information need  \\\n",
       "0  0.000000    0.085003                0.085003                     0.000000   \n",
       "1  0.113079    0.085999                0.085999                     0.113079   \n",
       "2  0.000000    0.000000                0.000000                     0.000000   \n",
       "\n",
       "   additional information would      also  also take  also take check  \\\n",
       "0                      0.111769  0.000000   0.000000         0.000000   \n",
       "1                      0.000000  0.000000   0.000000         0.000000   \n",
       "2                      0.000000  0.148122   0.148122         0.148122   \n",
       "\n",
       "      amant  amant vinegar  ...  would need  would need replicate     write  \\\n",
       "0  0.000000       0.000000  ...    0.111769              0.111769  0.000000   \n",
       "1  0.113079       0.113079  ...    0.000000              0.000000  0.113079   \n",
       "2  0.000000       0.000000  ...    0.000000              0.000000  0.000000   \n",
       "\n",
       "   write conclusion  write conclusion make       yar  yar expirement  \\\n",
       "0          0.000000               0.000000  0.000000        0.000000   \n",
       "1          0.113079               0.113079  0.226158        0.113079   \n",
       "2          0.000000               0.000000  0.000000        0.000000   \n",
       "\n",
       "   yar expirement three  yar result  yar result accurate  \n",
       "0              0.000000    0.000000             0.000000  \n",
       "1              0.113079    0.113079             0.113079  \n",
       "2              0.000000    0.000000             0.000000  \n",
       "\n",
       "[3 rows x 183 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tfidf_vectors(train_set_sample['EssayText'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
