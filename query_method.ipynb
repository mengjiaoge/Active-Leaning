{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arbitrary-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, division\n",
    "\n",
    "from scipy.sparse import csc_matrix, vstack\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveLearner(object):\n",
    "    \"\"\"Determine the optimal querying strategy for unlabeled data. \n",
    "    Suppose you're given a small set of labeled points, a large set of\n",
    "    unlabeled points, and in addition, you can request labels for n of your\n",
    "    unlabeled points. Active Learning provides a framework for choosing the\n",
    "    points whose labels will give us the most information.\n",
    "    \n",
    "    This class implements three types of uncertainty sampling: Least\n",
    "    confident (query the instances about which your model is least confident),\n",
    "    max margin (query the instances which have the smallest ratio between the\n",
    "    model's top two predictions), and entropy (query the instances whose model\n",
    "    output distributions have the most entropy).\n",
    "    \n",
    "    It also implements two types of query by committee: vote entropy (query\n",
    "    instances where the entropy amongst votes is maximized) and average kl\n",
    "    divergence (query instances of max kl divergence from the consensus).\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_queries : int or float or None, default=None\n",
    "        Number of queries to rank. None for rank all points, float for rank\n",
    "        percentage of unlabeled point, int for rank n unlabeled points.\n",
    "    strategy : 'entropy', 'least_confident', 'max_margin', 'vote_entropy',\n",
    "        'average_kl_divergence', default='least_confident'\n",
    "        Strategy for ranking unlabeled points as canditates for querying.\n",
    "    \"\"\"\n",
    "\n",
    "    _uncertainty_sampling_frameworks = [\n",
    "        'entropy',\n",
    "        'max_margin',\n",
    "        'least_confident',\n",
    "    ]\n",
    "\n",
    "    _query_by_committee_frameworks = [\n",
    "        'vote_entropy',\n",
    "        'average_kl_divergence',\n",
    "    ]\n",
    "\n",
    "    def __init__(self, strategy='least_confident'):\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def rank(self, clf, X_unlabeled, num_queries=None):\n",
    "        \"\"\"Rank unlabeled instances as querying candidates.\n",
    "        Parameters\n",
    "        ----------\n",
    "        clf : classifier\n",
    "            Pre-trained probabilistic classifier conforming to the sklearn\n",
    "            interface.\n",
    "        X_unlabeled : sparse matrix, [n_samples, n_features]\n",
    "            Unlabeled training instances.\n",
    "        Returns\n",
    "        -------\n",
    "        rankings : ndarray, shape (num_queries,)\n",
    "            cluster labels\n",
    "        \"\"\"\n",
    "        if num_queries == None:\n",
    "            num_queries = X_unlabeled.shape[0]\n",
    "\n",
    "        elif type(num_queries) == float:\n",
    "            num_queries = int(num_queries * X_unlabeled.shape[0])\n",
    "\n",
    "        if self.strategy in self._uncertainty_sampling_frameworks:\n",
    "            scores = self.__uncertainty_sampling(clf, X_unlabeled)\n",
    "\n",
    "        elif self.strategy in self._query_by_committee_frameworks:\n",
    "            scores = self.__query_by_committee(clf, X_unlabeled)\n",
    "\n",
    "        else: \n",
    "            raise ValueError(\n",
    "                \"I haven't implemented this strategy. Sorry.\"\n",
    "            )\n",
    "\n",
    "        rankings = np.argsort(-scores)[:num_queries]\n",
    "        return rankings\n",
    "\n",
    "    def __uncertainty_sampling(self, clf, X_unlabeled):\n",
    "        probs = clf.predict_proba(X_unlabeled)\n",
    "\n",
    "        if self.strategy == 'least_confident':\n",
    "            return 1 - np.amax(probs, axis=1)\n",
    "\n",
    "        elif self.strategy == 'max_margin':\n",
    "            margin = np.partition(-probs, 1, axis=1)\n",
    "            return -np.abs(margin[:,0] - margin[:, 1])\n",
    "\n",
    "        elif self.strategy == 'entropy':\n",
    "            return np.apply_along_axis(entropy, 1, probs)\n",
    "\n",
    "    def __query_by_committee(self, clf, X_unlabeled):\n",
    "        num_classes = len(clf[0].classes_)\n",
    "        C = len(clf)\n",
    "        preds = []\n",
    "\n",
    "        if self.strategy == 'vote_entropy':\n",
    "            for model in clf:\n",
    "                y_out = map(int, model.predict(X_unlabeled))\n",
    "                preds.append(np.eye(num_classes)[y_out])\n",
    "\n",
    "            votes = np.apply_along_axis(np.sum, 0, np.stack(preds)) / C\n",
    "            return np.apply_along_axis(entropy, 1, votes)\n",
    "\n",
    "        elif self.strategy == 'average_kl_divergence':\n",
    "            for model in clf:\n",
    "                preds.append(model.predict_proba(X_unlabeled))\n",
    "\n",
    "            consensus = np.mean(np.stack(preds), axis=0)\n",
    "            divergence = []\n",
    "            for y_out in preds:\n",
    "                divergence.append(entropy(consensus.T, y_out.T))\n",
    "            \n",
    "            return np.apply_along_axis(np.mean, 0, np.stack(divergence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
